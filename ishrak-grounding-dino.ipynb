{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARING GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, we import the `os` library, which allows us to interact with the operating system. We then use `os.getcwd()` to get the current working directory and store it in the variable `projectdir`. Finally, we print the value of `projectdir` to verify the current directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "projectdir = os.getcwd()\n",
    "print(projectdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, we set up our environment for the computer vision workshop. We import the `torch` library for deep learning and the `requests` library for downloading files from the internet. We also clone the GroundingDINO repository from GitHub, which contains the code we'll be using in this workshop. Finally, we install all the necessary packages listed in the `requirements.txt` file to ensure we have everything we need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "#install request package\n",
    "%pip install requests\n",
    "import requests\n",
    "\n",
    "# Clone the repository\n",
    "os.system(\"git clone https://github.com/IDEA-Research/GroundingDINO.git\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change directory to the cloned repository\n",
    "os.chdir(os.path.join(\"GroundingDINO\"))\n",
    "\n",
    "# Install the package in editable mode\n",
    "os.system(\"pip install -q -e .\")\n",
    "\n",
    "# Install the supervision package\n",
    "os.system(\"pip install supervision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, we create a directory called `weights` to store the weight file for our model. We then change our working directory to `weights` and download the weight file from a specified URL using the `requests` library. If the download is successful, we save the file in the `weights` directory and print a confirmation message. Otherwise, we print an error message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for weights\n",
    "weights_dir = os.path.join(projectdir,\"weights\")\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "# Change directory to the weights directory\n",
    "os.chdir(weights_dir)\n",
    "\n",
    "# Download the weight file\n",
    "weight_url = \"https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\"\n",
    "weight_filename = os.path.basename(weight_url)\n",
    "weight_filepath = os.path.join(weights_dir, weight_filename)\n",
    "\n",
    "response = requests.get(weight_url)\n",
    "if response.status_code == 200:\n",
    "    with open(weight_filepath, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(\"Weight file downloaded successfully.\")\n",
    "else:\n",
    "    print(f\"Failed to download weight file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOWNLOAD DATA IMAGE SAMPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell creates a directory called `data` to store images. We then change our working directory to `data` and download a set of images from specified URLs using the `requests` library. Each image is saved in the `data` directory with its respective filename. A confirmation message is printed for each successful download, and an error message is printed if a download fails.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for data\n",
    "data_dir = os.path.join(projectdir,\"data\")\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Change directory to the data directory\n",
    "os.chdir(data_dir)\n",
    "\n",
    "# URLs of the images to download\n",
    "image_urls = {\n",
    "    \"compass.jpg\": \"https://unsplash.com/photos/xu2WYJek5AI/download?ixid=M3wxMjA3fDB8MXxzZWFyY2h8MTV8fGNvbXBhc3N8ZW58MHx8fHwxNjg5MTc2NzMyfDA&force=true&w=960\",\n",
    "    \"air.jpg\": \"https://unsplash.com/photos/AlA8S9tALAs/download?ixid=M3wxMjA3fDB8MXxzZWFyY2h8MTR8fHBhcmFjaHV0ZXxlbnwwfHx8fDE2ODkwOTU1MTJ8MA&force=true&w=960\",\n",
    "    \"ocean.jpg\": \"https://unsplash.com/photos/1PWhYZ_erME/download?ixid=M3wxMjA3fDB8MXxhbGx8fHx8fHx8fHwxNjg5MDA2MTk5fA&force=true&w=960\",\n",
    "    \"snow.jpg\": \"https://unsplash.com/photos/MB1FuEh0AzU/download?ixid=M3wxMjA3fDB8MXxzZWFyY2h8NHx8c25vd2JvYXJkZXJzfGVufDB8MHx8fDE2ODkwMTk0NTB8MA&force=true&w=960\",\n",
    "    \"hardware.jpg\": \"https://unsplash.com/photos/lllK4-63KTw/download?ixid=M3wxMjA3fDB8MXxzZWFyY2h8Mnx8Ym9sdCUyMGFuZCUyMHdhc2hlcnxlbnwwfHx8fDE2ODkxNzg1NTN8MA&force=true&w=960\"\n",
    "}\n",
    "\n",
    "# Download each image\n",
    "for filename, url in image_urls.items():\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(os.path.join(data_dir, filename), 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"{filename} downloaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to download {filename}. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, we import the necessary modules and define paths for the GroundingDINO model configuration and weights. We then use the `load_model` function from the `groundingdino.util.inference` module to load the model with the specified configuration and weights. This prepares our\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groundingdino.util.inference import load_model\n",
    "\n",
    "# Define paths\n",
    "groundingdino_dir = os.path.join(projectdir, \"GroundingDINO\")\n",
    "model_config_path = os.path.join(groundingdino_dir, \"groundingdino/config/GroundingDINO_SwinT_OGC.py\")\n",
    "weights_path = os.path.join(projectdir, \"weights/groundingdino_swint_ogc.pth\")\n",
    "\n",
    "# Load model\n",
    "model = load_model(model_config_path, weights_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GD DETECT NORMAL IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, we perform object detection using the loaded GroundingDINO model. We define the image name, path, and text prompt for the detection, along with thresholds for boxes and text. We load the image using the `load_image` function and then use the `predict` function to perform object detection based on the specified text prompt. The detected objects are then annotated on the image using the `annotate` function. Finally, we display the annotated image using the `plot_image` function from the `supervision` module. This demonstrates the ability of our model to detect and highlight objects in an image based on textual descriptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import supervision as sv\n",
    "from groundingdino.util.inference import load_image, predict, annotate\n",
    "\n",
    "# Define constants and paths\n",
    "IMAGE_NAME = \"compass.jpg\"\n",
    "IMAGE_PATH = os.path.join(projectdir, \"data\", IMAGE_NAME)\n",
    "TEXT_PROMPT = \"compass\"\n",
    "BOX_THRESHOLD = 0.70\n",
    "TEXT_THRESHOLD = 0.25\n",
    "DEVICE = \"cpu\"  # Specify \"cpu\" as the device\n",
    "\n",
    "# Load image\n",
    "image_source, image = load_image(IMAGE_PATH)\n",
    "print(image.shape)\n",
    "\n",
    "# Perform object detection\n",
    "boxes, logits, phrases = predict(\n",
    "    model=model,\n",
    "    image=image,\n",
    "    caption=TEXT_PROMPT,\n",
    "    box_threshold=BOX_THRESHOLD,\n",
    "    text_threshold=TEXT_THRESHOLD,\n",
    "    device=DEVICE  # Pass \"cpu\" as the device\n",
    ")\n",
    "\n",
    "# Annotate the image\n",
    "annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
    "\n",
    "# Display the annotated image\n",
    "sv.plot_image(annotated_frame, (16, 16))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this cell, we apply the GroundingDINO model for object detection on a different image and text prompt. We define the image name as \"hardware.jpg\" and the text prompt as \"spanner\". \n",
    "\n",
    "The same process is followed as before: we load the image, perform object detection using the `predict` function with the specified text prompt and thresholds, and then annotate the detected objects on the image. Finally, we display the annotated image to visualize the results of our object detection task. This showcases the versatility of our model in detecting various objects based on textual descriptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import supervision as sv\n",
    "from groundingdino import load_image, predict, annotate\n",
    "\n",
    "# Define constants and paths\n",
    "IMAGE_NAME = \"hardware.jpg\"\n",
    "IMAGE_PATH = os.path.join(projectdir, \"data\", IMAGE_NAME)\n",
    "TEXT_PROMPT = \"spanner\"\n",
    "BOX_THRESHOLD = 0.70\n",
    "TEXT_THRESHOLD = 0.25\n",
    "DEVICE = \"cpu\"  # Specify \"cpu\" as the device\n",
    "\n",
    "# Load image\n",
    "image_source, image = load_image(IMAGE_PATH)\n",
    "\n",
    "# Perform object detection\n",
    "boxes, logits, phrases = predict(\n",
    "    model=model,\n",
    "    image=image,\n",
    "    caption=TEXT_PROMPT,\n",
    "    box_threshold=BOX_THRESHOLD,\n",
    "    text_threshold=TEXT_THRESHOLD,\n",
    "    device=DEVICE  # Pass \"cpu\" as the device\n",
    ")\n",
    "\n",
    "# Annotate the image\n",
    "annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
    "\n",
    "# Display the annotated image\n",
    "sv.plot_image(annotated_frame, (16, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GD + OPENCV/ Open Webcam and Snap frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, we expand the application of the GroundingDINO model to perform object detection on frames captured from a webcam. We define constants and paths for capturing and storing frames, along with the text prompt \"face\" for object detection. The process involves capturing frames at specified intervals, performing object detection on each frame using the `predict` function, annotating the detected objects, and finally displaying the annotated frames. This demonstrates how our model can be applied to real-time object detection in video streams or live camera feeds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import supervision as sv\n",
    "from groundingdino.util.inference import load_image, predict, annotate\n",
    "\n",
    "# Constants and paths\n",
    "IMAGE_FOLDER = \"snap\"\n",
    "TEXT_PROMPT = \"face\"\n",
    "BOX_THRESHOLD = 0.50\n",
    "TEXT_THRESHOLD = 0.25\n",
    "DEVICE = \"cpu\"  # Specify \"cpu\" as the device\n",
    "SNAP_INTERVAL = 2   # Interval to capture frames (in seconds)\n",
    "NUM_SNAPS = 5     # Total number of frames to capture\n",
    "\n",
    "# Change directory to the data directory\n",
    "os.chdir(projectdir)\n",
    "\n",
    "# Check if the image folder exists and delete its contents if it does\n",
    "if os.path.exists(IMAGE_FOLDER):\n",
    "    for filename in os.listdir(IMAGE_FOLDER):\n",
    "        file_path = os.path.join(IMAGE_FOLDER, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "# Create folder if it doesn't exist\n",
    "else:\n",
    "    os.makedirs(IMAGE_FOLDER)\n",
    "\n",
    "# Function to capture frames from webcam and save them to the folder\n",
    "def capture_frames(folder, interval, num_snaps):\n",
    "    cap = cv2.VideoCapture(0)  # 0 for default webcam\n",
    "    \n",
    "    time.sleep(2)  # Delay start by 2 seconds\n",
    "    \n",
    "    frame_count = 0\n",
    "    while frame_count < num_snaps:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        cv2.imshow('snap', frame)\n",
    "        frame_count += 1\n",
    "\n",
    "        # Save frame every interval seconds\n",
    "        image_name = f\"snap_{frame_count}.jpg\"\n",
    "        cv2.imwrite(os.path.join(folder, image_name), frame)\n",
    "\n",
    "        time.sleep(interval)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Function to annotate images in the folder\n",
    "def annotate_images(folder):\n",
    "    annotated_images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(folder, filename)\n",
    "            image_source, image = load_image(image_path)\n",
    "\n",
    "            # Perform object detection\n",
    "            boxes, logits, phrases = predict(\n",
    "                model=model,\n",
    "                image=image,\n",
    "                caption=TEXT_PROMPT,\n",
    "                box_threshold=BOX_THRESHOLD,\n",
    "                text_threshold=TEXT_THRESHOLD,\n",
    "                device=DEVICE\n",
    "            )\n",
    "\n",
    "            # Annotate the image\n",
    "            annotated_frame = annotate(image_source=image_source, boxes=boxes, logits=logits, phrases=phrases)\n",
    "            annotated_images.append((image_path, annotated_frame))\n",
    "\n",
    "    return annotated_images\n",
    "\n",
    "# Capture frames from webcam and save them\n",
    "capture_frames(IMAGE_FOLDER,SNAP_INTERVAL, NUM_SNAPS)\n",
    "\n",
    "# Annotate images in the folder and replace them\n",
    "annotated_images = annotate_images(IMAGE_FOLDER)\n",
    "for image_path, annotated_frame in annotated_images:\n",
    "    cv2.imwrite(image_path, annotated_frame)\n",
    "\n",
    "# Display annotated images\n",
    "for image_path, annotated_frame in annotated_images:\n",
    "    sv.plot_image(annotated_frame, (16, 16), f\"Annotated Image: {image_path}\")\n",
    "    \n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
